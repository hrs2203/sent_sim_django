# About the Project

## What is Semantic Similarity

## What is our project ( deliverables )

## How do we wish to achive our goal
1. Generate Embeddings for sentences
2. Compare those Embeddings

## Method's for generating Embedding
1. Using Semantic Nets and Corpus Statistics
2. Sentence Embeddings using Siamese BERT-Networks

## Method's Used for Comparing Embeddings
1. Cosine Based similarity

# Semantic Nets and Corpus Statistics
The proposed method derives text similarity from semanticand syntactic information contained in the compared texts. Unlike existing methods that use a fixed set of vocabulary, the proposed method dynamically forms a joint word set only using allthe distinct words in the pair of sentences.

for each sentence, a raw semantic vector is derived with the assistance of a lexical database. A word order vector isformed for each sentence, again using information from the lexical database.

Since each word in a sentence contributes differently to the meaning of the whole sentence, thesignificance of a word is weighted by using informationcontent derived from a corpus

By combining the rawsemantic vector with information content from the corpus, asemantic vector is obtained for each of the two sentences.

Semantic similarity is computed based on the two semantic vectors.
An word order similarity is calculated using the two order vectors.
Finally, the sentence similarity is derived bycombining semantic similarity and order similarity.

<img src="./images/corpus_img.png" />

## Semantic Similarity between Words
Here we are utilizing semantic knowledge base to compare words. For this project we are using <b>WordNet</b>

<img src="./images/Hierarchical_synset.png" />

In WordNet words are organized into synonym sets (synsets) in the knowledge base , with semantics and relation pointers to other synsets.


similarity between words is determined not only by path lengths but also by depth. We propose that the similaritys s(w1, w2) between words w1 and w2 as a function of path length and depth as follows:

<img src="./images/wordnet_word_sim.png" />

- l is the shortest path length between w1 and w2,
- h is the depth of subsumer in the hierarchical semantic nets.
- f1 and f2 are transfer functions of path length and depth,respectively.
- $\alpha$ is experimental constants.
- $\beta$ > 0 is a smoothing factor and $\beta$ $\to$ $\infty$ then the depth of a word in the semantic nets is not considered.

## Semantic Similarity between Sentences

Given two sentences,T1andT2, a joint word set is formed:

T = T1 $\cup$ T2

Since the joint word set is purely derived from thecompared sentences, it is compact with no redundantinformation. The joint word set,T, can be viewed as the <b>semantic information</b> for the compared sentences.

The vector derived from the joint word set iscalled the lexical semantic vector, denoted by $\tilde{s}$




## Word Order Similarity between Sentences
Let us consider a pair of sentences,T1andT2, that containexactly the same words in the same order with theexception of two words from T1 which occur in the reverse order in T2. For example:

- T1: A quick brown dog jumps over the lazy fox.
- T2: A quick brown fox jumps over the lazy dog.

For the example pair of sentencesT1andT2, the jointword set is:

- T : { A,quick,brown,dog,jumps,over,the,lazy,fox }

assign a unique index number for each word inT1andT2. The index number is simply the order number inwhich the word appears in the sentence.

indexes : { A : 0 , quick : 1 , brown : 2 , dog : 3 , jumps : 4 , over : 5 , the : 6 , lazy : 7 , fox : 8 }

word order vectors for T1 and T2 are r1 and r2, respectively.

- r1 : { 1 2 3 4 5 6 7 8 9 }
- r2 : { 1 2 3 9 5 6 7 8 4 }

The measure for measuring the wordorder similarity of two sentences is:

<img src="./images/ord_sim_img.png" />

## Overall Sentence Similarity

Both semantic and syntactic information (in terms ofword order) play a role in conveying the meaning ofsentences. Thus, the overall sentence similarity is defined asa combination of semantic similarity and word ordersimilarity:

<img src="./images/corpus_sim_img.png" />

where $\delta$ <1 decides the relative contributions of semanticand word order information to the overall similarity computation.


# Sentence Embeddings using Siamese BERT-Networks


# Datasets Used


# Dev Progress


# References

1. Y. Li, D. McLean, Z. A. Bandar, J. D. O'Shea and K. Crockett, "Sentence similarity based on semantic nets and corpus statistics," in IEEE Transactions on Knowledge and Data Engineering, vol. 18, no. 8, pp. 1138-1150, Aug. 2006, doi: 10.1109/TKDE.2006.130.

2. Miller, G.A., 1995. WordNet: a lexical database for English. Communications of the ACM, 38(11), pp.39-41.

3. Reimers, N. and Gurevych, I., 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084.

4. Devlin, J., Chang, M.W., Lee, K. and Toutanova, K., 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.

