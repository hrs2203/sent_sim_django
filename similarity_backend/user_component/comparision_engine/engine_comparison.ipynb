{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to all in this md\n",
    "\n",
    "- [ ] Calling Comparison APIs\n",
    "- [ ] Test Set Data to compare apis\n",
    "- [ ] Select metrics that should me used to compare APIs\n",
    "- [ ] Create list of metrics and visualizatinos needed to make this a nice presentable Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpus_based.sent_sim import CorpusBasedComparision\n",
    "from sent_bert.sent_sim_bert import MultiSentenceBertComparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20143834189646437"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusBasedComparision(\"nice day\", \"bad dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7998412847518921, 0.691921591758728, 1.000000238418579, 0.135232076048851]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiSentenceBertComparision([\"Nice Day\"],[\"Nice time\",\"good time\",\"Nice day\",\"bad dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.read_tsv import read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = read_file(\"./data/sick_data.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,10):\n",
    "#     s1, s2, ex = parsed_data[i][1],parsed_data[i][2], parsed_data[i][0]\n",
    "#     print( ex , \n",
    "#           CorpusBasedComparision(s1,s2)*5 ,\n",
    "#           float(MultiSentenceBertComparision([s1],[s2])[0][0])*5,\n",
    "#           s1, s2, \"\" , sep=\"\\n\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list\n",
    "\n",
    "- accuacy, precision\n",
    "- error\n",
    "- deviation\n",
    "- r2 error\n",
    "- FP-TN ( DA COURSE LAST SLIDES )\n",
    "- biases ( corpus stats (word order ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Corpus Based Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.92.93.94.95.96.97.98.99.100.101.102.103.104.105.106.107.108.109.110.111.112.113.114.115.116.117.118.119.120.121.122.123.124.125.126.127.128.129.130.131.132.133.134.135.136.137.138.139.140.141.142.143.144.145.146.147.148.149.150.151.152.153.154.155.156.157.158.159.160.161.162.163.164.165.166.167.168.169.170.171.172.173.174.175.176.177.178.179.180.181.182.183.184.185.186.187.188.189.190.191.192.193.194.195.196.197.198.199."
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for ind , (comp, s1, s2) in enumerate(parsed_data[:200]):\n",
    "    if ind%10 == 0 : print(ind, end=\".\")\n",
    "    results.append([ float(comp) , CorpusBasedComparision(s1,s2)*5 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8926977902486672"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MSE(result):\n",
    "    result = np.array([ (a-b)**2 for a,b in result])\n",
    "    return np.mean(result)\n",
    "MSE(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spearman Rank Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For SentBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.20.30.40.50.60.70.80.90.100.110.120.130.140.150.160.170.180.190.200.210.220.230.240.CPU times: user 28.1 s, sys: 91.4 ms, total: 28.2 s\n",
      "Wall time: 7.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentbert_results = []\n",
    "for ind , (comp, s1, s2) in enumerate(parsed_data[:250]):\n",
    "    if ind%10 == 0 : print(ind, end=\".\")\n",
    "    comp_val = MultiSentenceBertComparision( [ s1 ] , [s2] )[0][0]\n",
    "    sentbert_results.append([ float(comp) , comp_val*5 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9428939205703116"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(sentbert_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spearman Rank Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
